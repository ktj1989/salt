{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net with simple Resnet Blocks v2, can get 0.80+\n",
    "Original version : https://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks\n",
    "update log\n",
    "Cancel last dropout (seems better)\n",
    "modify convolution_block, to be more consistant with the standard resent model.\n",
    "https://arxiv.org/abs/1603.05027\n",
    "Use faster IOU metric score code,\n",
    "https://www.kaggle.com/donchuk/fast-implementation-of-scoring-metric\n",
    "Use binary_crossentropy loss and then Lovász-hinge loss (very slow!)\n",
    "Lovász-hinge loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "Limit the max epochs number to make the kernel finish in the limit of 6 hours, better score can be achived at more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_v5.model\n",
      "Unet_resnet_v5.csv\n"
     ]
    }
   ],
   "source": [
    "version = 5\n",
    "basic_name = f'Unet_resnet_v{version}'\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"~/kaggle/salt/input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"~/kaggle/salt/input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d051510d7f947da9efb39d178999003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"/home/ec2-user/kaggle/salt/input/train/images/{}.png\".format(idx), color_mode=\"grayscale\")) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a2755b3834487cb830d5bfdfac5e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"/home/ec2-user/kaggle/salt/input/train/masks/{}.png\".format(idx), color_mode=\"grayscale\")) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Coverage class')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Depth distribution')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the depth distributions¶\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(1)\n",
    "#             continue\n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101, 1)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 101, 101, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 101, 101, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 101, 101, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 101, 101, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 101, 101, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 101, 101, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 101, 101, 16) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 101, 101, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 101, 101, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 101, 101, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 101, 101, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 101, 101, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 101, 101, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 101, 101, 16) 0           conv2d_5[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 101, 101, 16) 64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 101, 101, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50, 50, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50, 50, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 50, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 50, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 50, 50, 32)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 50, 32)   128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 50, 50, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 50, 50, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 50, 50, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 50, 50, 32)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50, 50, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 25, 25, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 25, 25, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 12, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 12, 12, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 12, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 12, 12, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 12, 12, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 12, 128)  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 12, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 12, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 12, 12, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 12, 128)  0           conv2d_20[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 12, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 12, 12, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 6, 6, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 6, 6, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 6, 6, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 6, 6, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 6, 6, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 6, 6, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 6, 6, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 6, 6, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 6, 6, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 128)  147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 128)  147584      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 12, 128)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 12, 12, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 12, 12, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 128)  147584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 12, 12, 128)  0           conv2d_30[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 64)   36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 25, 25, 64)   0           conv2d_33[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 64)   256         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 64)   36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 25, 25, 64)   0           conv2d_35[0][0]                  \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 50, 50, 32)   128         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 50, 50, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 50, 50, 32)   9248        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 50, 50, 32)   128         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 50, 50, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 50, 50, 32)   9248        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 50, 50, 32)   0           conv2d_38[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 50, 50, 32)   128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 50, 50, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 50, 50, 32)   9248        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 50, 50, 32)   0           conv2d_40[0][0]                  \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 101, 101, 16) 64          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 101, 101, 16) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 101, 101, 16) 2320        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 101, 101, 16) 64          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 101, 101, 16) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 101, 101, 16) 2320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 101, 101, 16) 0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 101, 101, 16) 64          add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 101, 101, 16) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 101, 101, 16) 2320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 101, 101, 16) 64          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 101, 101, 16) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 101, 101, 16) 2320        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 101, 101, 16) 0           conv2d_45[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 101, 101, 16) 64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 101, 101, 16) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 101, 101, 1)  17          activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 101, 101, 1)  0           conv2d_46[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,119,857\n",
      "Trainable params: 5,112,497\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      " - 136s - loss: 0.3990 - my_iou_metric: 0.3922 - val_loss: 0.8179 - val_my_iou_metric: 0.2991\n",
      "\n",
      "Epoch 00001: my_iou_metric improved from -inf to 0.39220, saving model to Unet_resnet_v5.model\n",
      "Epoch 2/50\n",
      " - 85s - loss: 0.3345 - my_iou_metric: 0.4808 - val_loss: 1.2794 - val_my_iou_metric: 0.3611\n",
      "\n",
      "Epoch 00002: my_iou_metric improved from 0.39220 to 0.48075, saving model to Unet_resnet_v5.model\n",
      "Epoch 3/50\n",
      " - 85s - loss: 0.2855 - my_iou_metric: 0.5441 - val_loss: 0.4871 - val_my_iou_metric: 0.3970\n",
      "\n",
      "Epoch 00003: my_iou_metric improved from 0.48075 to 0.54414, saving model to Unet_resnet_v5.model\n",
      "Epoch 4/50\n",
      " - 85s - loss: 0.2515 - my_iou_metric: 0.5655 - val_loss: 0.4133 - val_my_iou_metric: 0.4159\n",
      "\n",
      "Epoch 00004: my_iou_metric improved from 0.54414 to 0.56548, saving model to Unet_resnet_v5.model\n",
      "Epoch 5/50\n"
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"/home/ec2-user/kaggle/salt/input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
